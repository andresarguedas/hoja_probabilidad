[
["contar.html", "Hoja de Referencia de Probabilidad 1 Contar 1.1 Regla de la multiplicación 1.2 Espacio muestral 1.3 Definición simple de probabilidad", " Hoja de Referencia de Probabilidad Andrea Vargas 2019-08-22 1 Contar 1.1 Regla de la multiplicación Supongamos que se tiene un experimento compuesto (experimento con múltiples componentes). Si el primer componente tiene \\(n_1\\) posibles resultados, el 2do tiene \\(n_2\\) posibles resultados, … , y el r-ésimo componente tiene \\(n_r\\) posibles resultados, entonces hay \\(n_1*n_2*\\dots*n_r\\) posibilidades para el experimento completo. knitr::include_graphics(“1.png”) 1.2 Espacio muestral knitr::include_graphics(“2.png”) Contiene el número de posibles muestras de tamaño \\(k\\) de una población de tamaño \\(n\\), bajo varios supuestos sobre como fue recolectada la muestra. Reemplazo Orden importa Orden no importa Con reemplazo \\(n^{k}\\) \\(\\displaystyle{n +k-1 \\choose k}\\) Sin remplazo \\(\\frac{n!}{(n-k)!}\\) \\(\\displaystyle{n \\choose k}\\) 1.3 Definición simple de probabilidad Si todos los resultados son igual de posibles, la probabilidad de que un evento A ocurra es: \\(P_{simple}(A)=\\frac{\\text{Numero de resultados favorables para A}}{\\text{Numero de resultados}}\\) "],
["condicional.html", "2 Pensando condicionalmente 2.1 Independencia 2.2 Uniones, Intersecciones y Complementos 2.3 Conjuntas, Marginales y Condicionales 2.4 Probabilidad de Unión o Intersección 2.5 La paradoja de Simpson: 2.6 Ley de la Probabilidad Total (LPT) 2.7 Regla de Bayes", " 2 Pensando condicionalmente 2.1 Independencia \\(\\textbf{Eventos Independientes:}\\) A y B son independientes si conociendo que el hecho de que A ocurrió no brinda información sobre si B ocurrió. Mas formalmente, A y B (lo cual tiene probabilidad de 0) son independientes si y solo si una de las siguientes sentencias equivalentes se cumple: \\(P(A\\displaystyle\\cap B) = P(A)P(B)\\) \\(P(A|B)=P(A)\\) \\(P(B|A)=P(B)\\) \\(\\textbf{Independencia condicional:}\\) A y B son condicionalmente independientes dado C si \\(P(A\\cap B|C) = P(A|C)P(B|C)\\). La independencia condicional no implica independencia, y la independencia no implica independencia condicional. 2.2 Uniones, Intersecciones y Complementos \\(\\textbf{Ley de De Morgan:}\\) Una identidad útil que puede hacer que el calculo de probabilidades de uniones sean mas fáciles es relacionándolas con las intersecciones y viceversa. Resultados análogos se mantienen con más de 2 grupos. \\((A \\cup B)^c = A^c \\cap B^c\\) \\((A \\cap B)^c = A^c \\cup B^c\\) 2.3 Conjuntas, Marginales y Condicionales \\(\\textbf{Probabilidad Conjunta:}\\) \\(P(A\\cap B)\\) y \\(P(A,B)\\) = Probabilidad de A y B \\(\\textbf{Probabilidad Marginal (Incondicional):}\\) \\(P(A)\\) = Probabilidad de A \\(\\textbf{Probabilidad Condicional:}\\) \\(P(A|B) = \\frac{P(A,B)}{P(B)}\\) = Probabilidad de A dado B \\(\\textbf{La Probabilidad Condicional es una probabilidad:}\\) \\(P(A|B)\\) es una función de probabilidad para cualquier \\(B\\) fija. Cualquier teorema que aplique para probabilidad también aplicqq para probabilidad condicional. 2.4 Probabilidad de Unión o Intersección \\(\\textbf{Intersección por condicionalidad:}\\) \\(P(A\\cup B) = P(A) + P(B) - P(A\\cap B)\\) \\(P(A\\cup B \\cup C) = P(A) + P(B) + P(C) - P(A\\cap B) - P(A \\cap C) - P(B \\cap C) + P(A\\cap B \\cap C)\\) 2.5 La paradoja de Simpson: knitr::include_graphics(“3.png”) Es posible tener \\(P(A|B,C) &lt; P(A|B^{c},C)\\) y \\(P(A|B,C^c) &lt; P(A|B^c,C^c)\\) pero también \\(P(A|B) &gt; P(A|B^c)\\) 2.6 Ley de la Probabilidad Total (LPT) Sea \\(B_1,B_2,B_3,...,B_n\\) una \\(\\textit{particion}\\) del espacio muestral (es decir, son disjuntas y su unión es el espacio muestral completo). \\(P(A) = P(A|B_1)P(B_1) + P(A|B_2)P(B_2) + ... + P(A|B_n)P(B_n)\\) \\(P(A) = P(A \\cap B_1) + P(A\\cap B_2) + .. + P(A\\cap B_n)\\) Para \\(\\textbf{LPT con condicionalidad extra}\\), solo se agrega otro evento \\(C!\\) \\(P(A|C) = P(A|B_1,C)P(B_1|C) + .. + P(A|B_n,C)P(B_n|C)\\) \\(P(A|C) = P(A\\cap B_1|C) + P(A\\cap B_2|C) + ... + P(A\\cap B_n|C)\\) Un caso especial de LPT con \\(B\\) y \\(B^c\\) como partición: \\(P(A) = P(A|B)P(B) + P(A|B^c)P(B^c)\\) \\(P(A) = P(A\\cap B) + P(C\\cap B^c)\\) 2.7 Regla de Bayes \\(\\textbf{La regla de Bayes con condicionalidad extra (solo se agrega C!)}\\) \\(P(A|B) = \\frac{P(B|A)P(A)}{P(B)}\\) \\(P(A|B,C) = \\frac{P(B|A,C)P(A|C)}{P(B|C)}\\) También se puede escribir \\(P(A|B,C) = \\frac{P(A,B,C)}{P(B,C)} = \\frac{P(B,C|A)P(A)}{P(B,C)}\\) \\(\\textbf{Forma de &quot;Odds&quot; de la Regla de Bayes}\\) \\(\\frac{P(A|B)}{P(A^c|B)} = \\frac{P(B|A)}{P(B|A^c)} \\frac{P(A)}{P(A^c)}\\) Los \\(\\textit{odds posteriores}\\) de A son la \\(\\textit{razón de verosimilitud}\\) por los \\(\\textit{odds anteriores}\\) "],
["variables-aleatorias-y-sus-distribuciones.html", "3 Variables aleatorias y sus distribuciones 3.1 CFD, PDF e Independencia", " 3 Variables aleatorias y sus distribuciones 3.1 CFD, PDF e Independencia \\(\\textbf{Función de probabilidad (PDF):}\\) Da la probabilidad que una variable \\(\\textit{discreta}\\) tiene para un valor \\(x\\) \\(p_X(x) = P(X=x)\\) knitr::include_graphics(“4.png”) La PDF satisface que: \\(p_X(x) \\ge 0\\) y $ _{x} p_X(x) = 1$ \\(\\textbf{Funcion de distribución (CDF):}\\) Da la probabilidad de que una variable aleatoria sea menor o igual a \\(x\\). \\(F_x(x) = P(X\\le x)\\) knitr::include_graphics(“5.png”) La CDF es una función continua y continua hacia la derecha con \\(F_X(x) \\rightarrow 0 cuando x \\rightarrow - \\infty\\) y \\(F_X(x) \\rightarrow 1\\) cuando \\(x \\rightarrow \\infty\\) \\(\\textbf{Independencia:}\\) Intuitivamente, dos variables aleatorias son independientes si conociendo el valor de una, no se logra conocer información de la otra. Dos muestras de variables aleatorias discretas X y Y son independientes si para todos los valores de x y y \\(P(X=x, Y=y) = P(X=x)P(Y=y)\\) "],
["valores-esperados-y-funcion-indicadora.html", "4 Valores esperados y Función indicadora 4.1 Valor esperado y Linealidad 4.2 Función Indicadora", " 4 Valores esperados y Función indicadora 4.1 Valor esperado y Linealidad \\(\\textbf{Valor esperado:}\\) (media, expectativa o promedio) es un promedio ponderado de los posibles resultados de nuestra variable aleatoria. Matemáticamente, si \\(x_1, x_2, x_3,...\\) son todos los distintos valores posibles que \\(X\\) puede tomar, entonces el valor esperado de \\(X\\) es \\(E(X) = \\sum_{i} x_iP(X=x_i)\\) knitr::include_graphics(“6.png”) \\(\\textbf{Linealidad:}\\) Para cualquier muestra de variables aleatorias \\(X\\) y \\(Y\\), y las constantes \\(a,b,c\\), \\(E(aX +bY+c) = aE(X) + bE(Y) +c\\) \\(\\textbf{Misma distribucion implica misma media:}\\) Si \\(X\\) y \\(Y\\) tienen la misma distribución, entonces \\(E(X) = E(Y)\\) y, de forma mas general: \\(E(g(X)) = E(g(Y))\\) \\(\\textbf{Valor esperado condicional:}\\) se define como un valor esperado pero condicionado a un evento \\(A\\) cualquiera \\(E(X|A)= \\sum_{x} x P(X=x|A)\\) 4.2 Función Indicadora \\(\\textbf{Función indicadora:}\\) es una variable aleatoria que toma los valores 1 o 0. Es el indicador de un evento: si el evento ocurre, el indicador es 1; de otra forma es 0. Son útiles para muchos problemas de contar cuantos eventos de un tipo ocurren. \\(I_A= \\left \\{ \\begin{matrix} 1 &amp; \\mbox{si }A\\mbox{ ocurre}\\\\ 0 &amp; \\mbox{si }A\\mbox{ no ocurre}\\end{matrix}\\right.\\) Note que \\(I^2_A= I_A, I_AI_B = I_{A \\cap B}\\), y \\(I_{A \\cup B =I_A + I_B-I_AI_B}\\). \\(\\textbf{Distribución}:I_A \\sim Bern(p)\\) donde \\(p=P(A)\\) \\(\\textbf{Puente fundamental}\\) El valor esperado de la función indicadora de un evento A es la probabilidad del evento A: \\(E(I_A) = P(A)\\). 4.2.1 Varianza y desviación estándar \\(Var(X)=E(X-E(X))^2 = E(X^2) - (E(X))^2\\) \\(SD(X) = \\sqrt{Var(X)}\\) "],
["va.html", "5 Va Continuas, LOTUS, UoU 5.1 Variables aleatorias continuas: 5.2 LOTUS 5.3 Universalidad de la Uniforme (UoU)", " 5 Va Continuas, LOTUS, UoU 5.1 Variables aleatorias continuas: \\(\\textbf{¿Cual es la probabilidad de que una v.a.c. este en un intervalo?}\\) Utilice la diferencia entre la funciones de distribución. \\(P(a\\le X \\le b) = P(X \\le b) - P(X \\le a) = F_X(b)-F_X(a)\\) Para \\(X \\sim N(\\mu, \\sigma^2)\\), esto se convierte en \\(P(a\\le X \\le b) = \\Phi \\Big(\\frac{b - \\mu}{\\sigma} \\Big) - \\Phi \\Big(\\frac{a-\\mu}{\\sigma} \\Big)\\) \\(\\textbf{¿Cual es la funcion de densidad? (PDF):}\\) La pdf es la derivada de la función de distribución. \\(F^, = f(x)\\) La función de densidad es no negativa e integra a 1. Por el teorema fundamental de calculo, para obtener la función de distribución desde la función de densidad, se hace la integral: \\(F(x) = \\int_{-\\infty}^{x} f(t) dt\\) knitr::include_graphics(“7.png”) Para encontrar la probabilidad de que una v.a.c. tome un valor en un intervalo, integre la PDF sobre ese intervalo \\(F(b)-F(a)=\\int_{a}^{b} f(x)dx\\) \\(\\textbf{¿Cómo encuentro el valor esperado de la funcion de distribucion?}\\) Análogo al caso discreto, donde la suma de \\(x\\) multiplicado por la función de probabilidad, para V.a.C se puede integrar \\(x\\) multiplicada por la función de densidad \\(E(X)= \\int_{-\\infty}^{\\infty} xf(x) dx\\) 5.2 LOTUS \\(\\textbf{Valor esperado de una funcion de v.a}\\) El valor esperado de \\(X\\) esta definido como: \\(E(X) = \\sum_x xP(X=x)\\) (para X discreta) \\(E(X) = \\int_{-\\infty}^{\\infty} xf(x) dx\\) (para X continua) La \\(\\textbf{Ley del Estadistico Inconsciente}\\) dice que se puede encontrar el valor esperado de una \\(\\textit{funcion de una v.a, g(x)}\\), de forma similar, reemplazando la x en frente de la función de densidad/probabilidad con g(x) y aún funciona con la función de densidad/probabilidad. $E(g(X)) = _x g(x) P(X=x) $ (para X discreta) \\(Eg((X)) = \\int_{-\\infty}^{\\infty} g(x)f(x) dx\\) (para X continua) \\(\\textbf{¿Cuál es la función de una variable aleatoria?}\\) La función de una v.a es también una v.a. Por ejemplo, si X es el número de bicicletas que usted puede ver en una hora, entonces \\(g(X) = 2X\\) es el número de llantas de bicicletas que usted puede ver en una hora y \\(h(X) = \\displaystyle{X \\choose 2}\\) es el número de \\(\\textit{pares}\\) de bicicletas que ve en esa hora. \\(\\textbf{¿Cual es el objetivo?}\\) No se necesita saber la función de probabilidad/densidad de g(X) para obtener su valor esperado. Solo se necesita la función de probabilidad/densidad de X. 5.3 Universalidad de la Uniforme (UoU) Cuando se introduce una v.a.c en su propia función de distribución, se obtiene una variable Uniforme(0,1). Cuando se introduce una v.a Uniforme(0,1) en una función de distribución inversa, se obtiene una v.a. con esa función de distribución. Por ejemplo, digamos que una variable aleatoria X tiene una función de distribución \\(F(x) = 1 - e^{-x} , si x &gt; 0\\) Gracias a UoU, si introducimos X en esta función y obtenemos un v.a. uniforme \\(F(X) = 1 - e^{-x} \\sim Unif(0,1)\\) Similarmente, si \\(U \\sim Unif(0,)\\) entonces \\(F^{-1}(U)\\) tiene una CDF, F. El punto clave es que a cualquier v.a.c \\(X\\), podemos transformarla en una variable Uniforme y viceversa, usando su CDF. "],
["momentos.html", "6 Momentos y Funciones generadoras de momentos 6.1 Momentos 6.2 Funciones generatrices de momentos", " 6 Momentos y Funciones generadoras de momentos 6.1 Momentos Describen la forma de un distribución. Sea X una v.a. con media igual a \\(\\mu\\) y desviación estándar \\(\\sigma\\), y \\(Z=(X-\\mu)/\\sigma\\) es la versión \\(\\textit{estandarizada}\\) de X. El k-ésimo momento de X es \\(\\mu_k = E(X^k)\\) y el k-ésimo momento estandarizado de X es \\(m_k=E(Z^k)\\). La media, varianza, asimetría y curtosis son resúmenes importantes de la forma de una distribución. \\(\\textbf{Media:} E(X) =\\mu_1\\) \\(\\textbf{Varianza:}Var(X) = \\mu_2 - \\mu^2_1\\) \\(\\textbf{Asimetría:} Skew(X) =m_3\\) \\(\\textbf{Curtosis:} Kurt(X)=m_4-3\\) 6.2 Funciones generatrices de momentos \\(\\textbf{FGM:}\\) Para cualquier variable X, la función \\(M_X(t) = E(e^{tX)}\\) es la \\(\\textbf{funcion generatriz de momentos}\\) de X, si existe para cualquier valor de \\(t\\) en un intervalo abierto que contiene a 0. La variable \\(t\\) también podría haberse llamado \\(u\\) o \\(v\\). Es una herramienta de registro que nos deja trabajar con la función \\(función\\) \\(M_X\\) en lugar de la \\(secuencia\\) de momentos. \\(\\textbf{¿Por qué se llama la función generatriz de momentos?}\\) Porque la \\(k-ésima\\) derivada de la función generatriz de momentos, evaluado en 0, es el \\(k-ésimo\\) momento de X. \\(\\mu_k=E(X^k) = M_X^{(k)}(0)\\) Esta es la expansión de Taylor de \\(e^{tX}\\) ya que \\(M_X(t) = E(e^{tX}) = \\displaystyle\\sum_{k=0}^\\infty \\frac{E(X^k)t^k}{k!} = \\displaystyle\\sum_{k=0}^\\infty \\frac{\\mu_k t^k}{k!}\\) \\(\\textbf{FGM de funciones lineales}\\) Si tenemos \\(Y = aX + b\\) entonces \\(M_Y(t) = E(e^{t(aX+b)})=e^{bt}E(e^{(at)X})=e^{bt}M_X(at)\\) \\(\\textbf{Unicidad}\\) Si \\(existe\\), la FGM \\(\\text{determina de forma única la distribución}\\). Esto significa que para dos variables X y Y, tienen la misma distribución si y solo si sus FGM son iguales. \\(\\text{Sumar V.A independientes multiplicando sus FGM}\\) Si X y Y son independientes, entonces \\(M_{X+Y}(t) = E(e^{t(X+Y)})=E(e^{tX})E(e^{tY})=M_X(t) * M_Y(t)\\) La FGM de la suma de dos variables aleatorias es el producto de las FGMs de estas dos variables aleatorias. "],
["pdf.html", "7 PDFs y CDFs conjuntas 7.1 Distribuciones conjuntas 7.2 Distribuciones Condicionales 7.3 Distribuciones Marginales 7.4 Independencia de Variables Aleatorias 7.5 LOTUS multivariado", " 7 PDFs y CDFs conjuntas 7.1 Distribuciones conjuntas La función de distribución conjunta de X y Y es \\(F(x,y)=P(X\\leq x, Y \\leq y)\\) En el caso discreto X y Y tienen la \\(\\textbf{PMF conjunta}\\) \\(p_{X,Y}(x,y)= P(X=x, Y=y).\\) En el caso continuo, tienen una \\(\\textbf{PDF conjunta}\\) \\(f_{X,Y}(x,y)=\\frac{\\partial^2 }{\\partial x \\partial y} F_{X,Y}(x,y).\\) La PMF,PDF conjunta debe ser no negativa y sumar/integrar a 1. knitr::include_graphics(“8.png”) 7.2 Distribuciones Condicionales \\(\\textbf{Regla condicional y de Bayes para v.a. discreta}\\) \\(P(Y=y|X=x)= \\frac{P(X=x, Y=y)}{P(X=x)}=\\frac{P(X=x|Y=y)P(Y=y)}{P(X=x)}\\) \\(\\textbf{Regla condicional y de Bayes para v.a. continuas}\\) \\(f_{Y|X}(y|x)=\\frac{f_{X,Y}(x,y)}{f_X(x)}=\\frac{f_{X|Y}(x|y)f_Y(y)}{f_X(x)}\\) \\(\\textbf{La regla híbrida de Bayes}\\) \\(f_X(x|A)=\\frac{P(A|X=x)f_X(x)}{P(A)}\\) 7.3 Distribuciones Marginales Para encontrar la distribución de una (o más) variables aleatorias a partir de una PMF/PDF conjunta, se debe sumar/integrar sobre la variable aleatoria que no interesa. \\(\\textbf{PMF marginal a partir de una PMF conjunta}\\) \\(P(X=x)=\\displaystyle\\sum_{y}P(X=x, Y=y)\\) \\(\\textbf{PDF marginal a partir de una PDF conjunta}\\) \\(f_X(x)=\\displaystyle\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)\\, dy\\) 7.4 Independencia de Variables Aleatorias Las variables aleatorias X y Y son independientes si y solo si cualquiera de las siguientes condiciones se cumple: \\(\\bullet\\) La CDF conjunta es el producto de las CDFs marginales \\(\\bullet\\) La PMF/PDF conjunta es el producto de las PMFs/PDFs marginales \\(\\bullet\\) La distribución condicional de Y dado X es la distribución marginal de Y Escriba X \\(\\perp\\) Y para denotar que X y Y son independiente 7.5 LOTUS multivariado LOTUS en más de una dimensión es el análogo de LOTUS de una dimensión. Para variables aleatorias discretas: \\(E(g(X,Y))=\\displaystyle\\sum_{x}\\displaystyle\\sum_{y} g(x,y)P(X=x, Y=y)\\) Para variables aleatorias continuas: \\(E(g(X,Y))=\\displaystyle\\int_{-\\infty}^{\\infty}\\displaystyle\\int_{-\\infty}^{\\infty} g(x,y)f_{X,Y}(x,y)dxdy\\) "],
["cov.html", "8 Covarianza y Transformaciones 8.1 Covarianza y Correlación 8.2 Transformaciones 8.3 Convoluciones", " 8 Covarianza y Transformaciones 8.1 Covarianza y Correlación \\(\\textbf{La covarianza}\\) es el análogo de la varianza para dos variables aleatorias. \\(Cov(X,Y)=E((X-E(X))(Y-E(Y)))=E(XY)-E(X)E(Y)\\) Note que \\(Cov(X,X)=E(X^2)-(E(X))^2=Var(X)\\) \\(\\textbf{La correlación}\\) es una versión estandarizada de la covarianza que siempre está entre -1 y 1 \\(Corr(X,Y)=\\frac{Cov(X,Y)}{\\sqrt{Var(X)Var(Y)}}\\) \\(\\textbf{Covarianza e Independencia}\\) Si dos variables aleatorias son independientes, entonces no se correlacionan. El inverso no siempre es cierto. (e.j., considere \\(X~N(0,1)\\) y \\(Y=X^2\\)). \\(X \\perp Y \\longrightarrow Cov(X,Y) = 0 \\longrightarrow E(XY) = E(X)E(Y)\\) \\(\\textbf{Covarianza y Varianza}\\) La varianza de una suma se puede encontrar de la forma \\(Var(X+Y)=Var(X)+Var(Y)+2Cov(X,Y)\\) \\(Var(X_1+X_2+...+X_n)= \\displaystyle\\sum_{i=1}^{n}Var(X_i)+2\\displaystyle\\sum_{i&lt;j}Cov(X_i, X_j)\\) Si X y Y son independientes entonces tienen covarianza 0, entonces \\(X \\perp Y \\Longrightarrow Var(X+Y)=Var(X)+Var(Y)\\) Si \\(X_1, X_2,...,X_n\\) están idénticamente distribuidas y tienen la misma relación de covarianza (comúnmente por simetría), entonces \\(Var(X_1 + X_2 + ... + X_n)=nVar(X_1)+2 \\binom{n}{2}Cov(X_1, X_2)\\) \\(\\textbf{Propiedades de la Covarianza}\\) Para las v.a. W,X,Y y Z y las constantes a,b: \\(Cov(X,Y)=Cov(Y,X)\\) \\(Cov(X+a, Y+b)=Cov(X,Y)\\) \\(Cov(aX,bY)=abCov(X,Y)\\) \\(Cov(W+X,Y+Z)=Cov(W,Y)+Cov(W,Z)+Cov(X,Y)+COv(X,Z)\\) \\(\\textbf{La correlación es una invariante de locación y de escala}\\) Para cualquier constantes a,b,c,d con a y c diferentes a 0, \\(Corr(aX +b,cY+d)=Corr(X,Y)\\) 8.2 Transformaciones \\(\\textbf{Transformaciones de una variable}\\) Digamos que tenemos una variable aleatoria \\(X\\) con PDF \\(f_X(x)\\), pero también estamos interesados en una función de \\(X\\). Le decimos a esta función \\(Y=g(X)\\). También digamos que \\(y=g(x)\\). Si \\(g\\) es diferenciable y estrictamente creciente o estrictamente decreciente, entonces la PDF de Y es \\(f_Y(y)=f_X(x) \\Big| \\frac{dx}{dy} \\Big| = f_X(g^{-1}(y)) \\Big| \\frac{d}{dy} g^{-1}(y) \\Big|\\) La derivada de la transformación inversa se llama el \\(\\textbf{Jacobiano}\\) \\(\\textbf{Transformaciones de dos variables}\\) Similarmente, digamos que sabemos la PDF conjunta de U y V pero también estamos interesado en el vector aleatorio \\((X,Y)\\) definido por \\((X,Y)=g(U,V)\\). Entonces \\(\\frac{\\partial(u,v)}{\\partial(x,y)}= \\begin{pmatrix} \\frac{\\partial u}{\\partial x} &amp; \\frac{\\partial u}{\\partial y} \\\\ \\frac{\\partial v}{\\partial x} &amp; \\frac{\\partial v}{\\partial y} \\end{pmatrix}\\) Es la \\(\\textbf{Matriz Jacobiana}\\). Si las entradas en esta matriz existen y son continuas, y el determinante es diferente de 0, entonces \\(f_{X,Y}(x,y)=f_{U,V}(u,v) \\begin{Vmatrix} \\frac{\\partial (u,v)}{\\partial (x,y)}\\end{Vmatrix}\\) Las barras internas nos dicen que tomemos el determinante de la matriz, y las linea externas nos dicen que tomemos el valor absoluto. En una matriz \\(2 \\times 2\\), \\(\\begin{Vmatrix} a &amp; b \\\\ c &amp; d\\end{Vmatrix}= |ad - bc|\\) 8.3 Convoluciones \\(\\textbf{Integral de convolución}\\) SI usted quiere encontrar la PDF de la suma de dos v.a.c. X y Y, puede hacer la siguiente integral: \\(f_{X+Y}(t)= \\displaystyle\\int_{-\\infty}^{\\infty}f_X(x)f_Y(t-x)dx\\) \\(\\textbf{Ejemplo:}\\) Sean \\(X,Y~N(0,1)\\) i.i.d. Además para cada \\(t\\), \\(f_{X+Y}(t)=\\displaystyle\\int_{-\\infty}^{\\infty}\\frac{1}{\\sqrt{2 \\pi}}e^{-x^2/2} \\frac{1}{\\sqrt{2 \\pi}}e^{-(t-x)^2/2}dx\\) Completando el cuadrado y usando el hecho de que una PDF Normal integra a 1, esto termina siendo una \\(f_{X+Y}(t)\\) específicamente una PDF \\(N(0,2)\\). "],
["poisson.html", "9 Proceso de Poisson", " 9 Proceso de Poisson \\(\\textbf{Definición}\\) Tenemos un \\(\\textbf{Proceso de Poisson}\\) de grado \\(\\lambda\\) por unidad de tiempo si alguna de las siguientes condiciones se cumple: El número de llegadas en un intervalo de tiempo de longitud \\(t\\) es \\(Pois(\\lambda t)\\). Los números de llegadas en intervalos de tiempo disjuntos son independientes. Por ejemplo, los números de llegadas en los intervalos de tiempo \\([0,5], (5,12)\\) y \\([13,23)\\) son independientes con distribuciones \\(Pois(5\\lambda), Pois(7\\lambda), Pois(10\\lambda)\\) respectivamente. knitr::include_graphics(“9.png”) \\(\\textbf{Dualidad Tiempo-Conteo}\\) Considere un proceso de Poisson de correos llegando a una bandeja de entrada a un ritmo de \\(\\lambda\\) correos por hora. Sea \\(T_n\\) el tiempo de llegada de el \\(n- ésimo\\) correo (relativo a un tiempo de inicio 0) y sea \\(N_t\\) el numero de correos que llegan en \\([0,t]\\). Encontremos la distribución de \\(T_1\\). El evento \\(T_1&gt;1\\), el evento en el que se tiene que esperar más de \\(t\\) horas para recibir el primer correo, es el mismo evento que \\(N_t = 0\\), es decir, el evento en el que no hay correos en las primeras \\(t\\) horas. Entonces \\(P(T_1 &gt; t) = P(N_t = 0)=e^{-\\lambda t} \\longrightarrow P(T_1 \\leq t) = 1-e^{-\\lambda t}\\) Tenemos \\(T_1 \\sim Expo(\\lambda)\\). Por la propiedad de la Exponencial de no tener memoria y razonamiento similar, los tiempos entre llegadas entre los correos son i.i.d. \\(Expo(\\lambda)\\), e.j., las diferencias \\(T_n - T_{n-1}\\) son i.i.d. \\(Expo(\\lambda)\\). "],
["orden.html", "10 Estadísticos de Orden", " 10 Estadísticos de Orden \\(Definición\\) Digamos que usted tiene \\(n\\) v.a. \\(X_1, X_2,...,X_n\\) i.i.d. Si lo ordenamos de menor a mayor, el \\(i-ésimo\\) elemento es el \\(i-ésimo\\) estadístico de orden, denotado \\(X_{(i)}\\). Entonces \\(X_{(1)}\\) es el menor en la lista y \\(X_{(n)}\\) es el mayor. Note que los estadísticos de orden son \\(dependientes\\), e.j. conociendo \\(X_{(4)}=42\\) da la información de que \\(X_{(1)}, X_{(2)}, X_{(3)}\\) son \\(\\leq 42\\) y \\(X_{(5)}, X_{(6)},...,X_{(n)}\\) son \\(\\ge 42\\). \\(\\textbf{Distribución}\\) Tomando \\(n\\) variables aleatorias i.i.d. \\(X_{1}, X_2,...,X_n\\) con CDF \\(F(x)\\) y PDF \\(f(x)\\), la CDF y la PDF de \\(X_{(i)}\\) son: \\(F_{X_{(i)}}(x) = P(X_{(i)}\\le x)=\\displaystyle\\sum_{k=i}^{n} \\binom{n}{k} F(x)^k (1-F(x))^{n-k}\\) \\(f_{X_{(i)}}(x) = n\\binom{n-1}{i-1} F(x)^{i-1} (1-F(x))^{n-i}f(x)\\) \\(\\textbf{Estadísticos de orden uniformes}\\) El \\(j-ésimo\\) estadístico de orden de los \\(U_1,...,U_n\\)~\\(Unif(0,1)\\) i.i.d. es \\(U_{(j)}\\)~\\(Beta(j,n-j+1)\\) "],
["espercond.html", "11 Esperanza Condicional", " 11 Esperanza Condicional \\(\\textbf{Condicionando con un Evento}\\) Podemos encontrar \\(E(Y|A)\\), el valor esperado de \\(Y\\) dado que un evento \\(A\\) ocurrió. Un caso muy importante es cuando \\(A\\) es el evento \\(X=x\\). Note que \\(E(Y|A)\\) es un \\(número\\). Por ejemplo: \\(\\bullet\\) El Valor esperado de una tirada de un dado justo, dado que es primo, es \\(\\frac{1}{3}*2+\\frac{1}{3}*3+\\frac{1}{3}*5=\\frac{10}{3}\\) \\(\\bullet\\) Sea \\(Y\\) el número de éxitos en 10 pruebas independientes de Bernoulli con probabilidad \\(p\\) de éxito. Sea \\(A\\) el evento de que las primeras 3 pruebas sean éxitos. Entonces \\(E(Y|A)=3+7p\\) dado que el número de éxitos entre las 7 pruebas es \\(Bin(7,p)\\) \\(\\bullet\\) Sea \\(T\\)~\\(Expo(1/10)\\) el tiempo que debe esperar hasta que el bus llegue. Dado que usted ya ha esperado \\(t\\) minutos, el tiempo de espera adicional esperado es 10 minutos más. Esto es \\(E(T|T&gt;t)=t+0\\). Y Discreta Y Continua \\(E(Y)=\\sum_{y} yP(Y=y)\\) \\(E(Y)=\\int_{-\\infty}^{\\infty} y f_Y(y)dy\\) \\(E(Y|A)=\\sum_{y} yP(Y=y|A)\\) \\(E(Y|A)=\\int_{-\\infty}^{\\infty} y f_Y(y|A)dy\\) \\(\\textbf{Condicionando con una variable aleatoria}\\) También podemos encontrar \\(E(Y|X)\\), el valor esperado de \\(Y\\) dada la variable aleatoria \\(X\\). Esto es un \\(\\text{función de la variable aleatoria X}\\). Esto \\(no\\) es un número excepto en algunos casos específicos como si \\(X \\perp Y\\). Para encontrar \\(E(Y|X)\\), encuentre \\(E(Y|X=x)\\) y luego sustituya \\(X\\) por \\(x\\). Por ejemplo: \\(\\bullet\\) Si \\(E(Y|X=x)=x^3+5x\\), entonces \\(E(Y|X)=X^3+5X\\). \\(\\bullet\\) Sea \\(Y\\) el número de éxitos en 10 pruebas independientes de Bernoulli con probabilidad de éxito \\(p\\) y sea \\(X\\) el número de éxitos en las primeras 3 pruebas. Entonces \\(E(Y|X)=X+7p\\) \\(\\bullet\\) Se \\(X\\)~\\(N(0,1)\\) y \\(Y=X^2\\). Entonces \\(E(Y|X=x)=x^2\\) ya que sabemos que \\(X=x\\) y que \\(Y=x^2\\). Y \\(E(X|Y=y)=0\\) y que sabemos que \\(Y=y\\) y que \\(X= \\pm \\sqrt{y}\\), con iguales probabilidades (por simetría). Entonces \\(E(Y|X)=X^2\\), \\(E(X|Y)=0\\). \\(\\textbf{Propiedades del Valor Esperado Condicional}\\) \\(E(Y|X)=E(Y)\\)si \\(X \\perp Y\\) \\(E(h(X)W|X)=h(X)E(W|X)\\textbf{quitando lo que es conocido}\\) \\(E(E(Y|X))=E(Y)\\) \\(\\textbf{Ley de Adam=Ley de la Esperanza Total}\\) \\(\\textbf{Ley de Adam (Ley de la Esperanza Total)}\\) \\(Var(Y)=E(Var(Y|X)) + Var(E(Y|X))\\) "],
["tlc.html", "12 LGN, TLC 12.1 Ley de los Grandes Número (LGN) 12.2 Teorema del Límite Central (TLC)", " 12 LGN, TLC 12.1 Ley de los Grandes Número (LGN) Sea \\(X_1, X_2, X_3,...\\) i.i.d. con media \\(\\mu\\). La \\(\\textbf{media muestral}\\) es \\(\\bar X_n=\\frac{X_1+X_2+X_3+...+X_n}{n}\\) La \\(\\textbf{Ley de los Grandes Números}\\) dice que cuando \\(n \\rightarrow \\infty\\), \\(\\bar X_n \\rightarrow \\mu\\) con probabilidad 1. Por ejemplo, al tirar una moneda con probabilidad \\(p\\) de cara, sea \\(X_j\\) el indicador del \\(j-ésimo\\) intento que es cara. La LGN dice que la proporción de Caras converge a \\(p\\) (con probabilidad 1). 12.2 Teorema del Límite Central (TLC) \\(\\textbf{Aproximando con el TLC}\\) Utilizamos \\(\\dot \\sim\\) para denotar que es \\(aproximadamente distribuido\\). Podemos usar el \\(\\textbf{Teorema del Límite Central}\\) para aproximar la distribución de una variable aleatoria \\(Y=X_ + X_2 + ... + X_n\\) que es la suma de \\(n\\) i.i.d. variables aleatorias \\(X_i\\). Sea \\(E(Y)= \\mu_Y\\) y \\(Var(Y)=\\sigma ^2 _y\\). El TLC dice que \\(Y \\sim N(\\mu_y, \\sigma^2 _y)\\) Si las \\(X_i\\) son i.i.d. con media \\(\\mu_X\\) y varianza \\(\\sigma^2 _X\\), entonces \\(\\mu_Y=n\\mu_X\\) y \\(\\sigma^2_Y=n\\sigma^2_X\\). Para la media muestral \\(\\bar X_n\\), el TLC dice \\(\\bar X_n = \\frac{1}{n}(X_1+X_2+...+X_n)\\sim N(\\mu_X, \\sigma^2_x/n)\\) \\(\\textbf{Distribuciones sintóticas utilizando el TLC}\\) Usamos \\(\\xrightarrow{\\;\\; D \\;\\; }\\) para denotar que \\(\\textit{converge en distribución a}\\) conforme \\(n \\rightarrow \\infty\\). El TLC dice que si estandarizamos la suma \\(X_1+X_2+...+X_n\\) entonces la distribución de la suma converge a \\(N(0,1)\\) conforme \\(n \\rightarrow \\infty\\): \\(\\frac{1}{\\sigma \\sqrt{y}}(X_1+...+X_n-n\\mu_X)\\xrightarrow{\\;\\; D \\;\\; } N(0,1)\\) "],
["markov.html", "13 Cadenas de Markov 13.1 Definición 13.2 Propiedades de los estados 13.3 Matriz de transición 13.4 Propiedades de la cadena 13.5 Distribución Estacionaria 13.6 Caminata Aleatoria en una Red Indirecta", " 13 Cadenas de Markov 13.1 Definición knitr::include_graphics(“10.png”) Una Cadena de Markov es una caminata aleatoria en un espacio de estados, el cual asumimos que es finito, digamos {\\(1,2,...,M\\)}.Decimos que \\(X_t\\) denota cual elemento del espacio de estados de la caminata es visitado en el tiempo \\(t\\). La Cadena de Markov es la secuencia de variables aleatorias que rastrean donde está la caminata en todos los puntos del tiempo, \\(X_0, X_1, X_2,...\\). Por definición una Cadena de Markov tiene que cumplir con la \\(\\textbf{propiedad de Markov}\\), la cual dice que si usted quiere predecir donde la cadena va a estar en el futuro, si conocemos en estado presente entonces toda la historia pasada es irrelevante. \\(\\textit{Dado el presente, el pasado y futuro son condicionalmente independientes}\\). En símbolos, \\(P(X_{n+1}=j|X_0=i_0, X_1=i_1,...,X_n=i)=P(X_{n+1}=j|X_n=i)\\) 13.2 Propiedades de los estados Un estado es recurrente o transitorio. \\(\\bullet\\) Si empieza con un \\(\\textbf{estado recurrente}\\), entonces siempre va a volver al estado en algún punto en el futuro. \\(\\bullet\\) De otra forma, se está en un \\(\\textbf{estado transitorio}\\). Hay una probabilidad positiva de que una vez que se vaya de ahí, nunca vuelva. Un estado es periódico o aperiódico \\(\\bullet\\) Si empieza en un \\(\\textbf{estado periódico}\\) de periodo k, entonces el MCD de los posibles números de pasos que se necesitarían para volver es \\(k&gt;1\\). \\(\\bullet\\) De otra forma, se encuentra en un \\(\\textbf{estado aperiódico}\\). El MCD de los posibles números de pasos que se necesitarían para volver es 1. 13.3 Matriz de transición Sea {\\(1,2,..,M\\)} el espacio de estados. La matriz de transición \\(Q\\) es la matriz \\(M \\times M\\) donde el elemento \\(q_{ij}\\) es la probabilidad de que la cadena cambie del estado \\(i\\) al estado \\(j\\) en un paso: \\(q_{ij}=P(X_{n+1}=j|X_n=i)\\) Para encontrar la probabilidad de que la cadena cambie del estado \\(i\\) al estado \\(j\\) en exactamente \\(m\\) pasos, tome el \\((i,j)\\) elemento de \\(Q^m\\). \\(q_{ij}^{(m)}=P(X_{n+m}=j|X_n =i)\\) Si \\(X_0\\) está distribuida de acuerdo a vector fila PMF \\(\\vec{p}\\), e.j., \\(p_j=P(X_0=j)\\), entonces el PMF de \\(X_n\\) es \\(\\vec{p}Q^n\\). 13.4 Propiedades de la cadena Una cadena es \\(\\textbf{irreducible}\\) si se puede ir de un lugar a cualquier otro. Si una cadena (en un espacio de estados infinito) es irreducible, entonces todos sus estados son recurrentes. Una cadena es \\(\\textbf{periódica}\\) si cualquiera de sus estado es periódica, y es aperiódica si ninguno de sus estados es periódico. En una cadena irreducible, todos los estado tienen el mismo periodo. Una cadena es \\(\\textbf{reversible}\\) con respecto a \\(\\vec{s}\\) si \\(s_iq_{ij}=s_jq_{ji}\\) para todo \\(i,j\\). Ejemplos de cadenas reversibles incluyen cualquier cadena con \\(q_{ij}=q_{ji}\\), con \\(\\vec{s}=(\\frac{1}{M}, \\frac{1}{M},...,\\frac{1}{M})\\), y una caminata aleatoria en una red no dirigida. 13.5 Distribución Estacionaria Digamos que el vector \\(\\vec{s}=(s_1, s_2,...,s_M)\\) es una PMF (escrito como un vector fila). Le diremos \\(\\textbf{distribución estacionaria}\\) de la cadena a \\(\\vec{s}\\) si \\(\\vec{s}Q=\\vec{s}\\). Como consecuencia, si \\(X_t\\) tiene la distribución estacionaria, entonces todas las futuras \\(X_{t+1}, X_{t+2},...\\) tienen la distribución estacionaria. Para cadenas irreducibles y aperiódicas, la distribución estacionaria existe, es única y \\(s_i\\) es la probabilidad a largo plazo de que una cadena este en el estado \\(i\\). El número esperado de pasos para volver a \\(i\\) empezando en \\(i\\) es \\(1/s_i\\). Para encontrar la distribución estacionaria, también puede resolver la ecuación matricial \\((Q&#39; - I)\\vec{s}&#39; =0\\). La distribución estacionaria es uniforme si las columnas de \\(Q\\) suman 1. \\(\\textbf{La condición de reversibilidad implica estacionariedad}\\) Si usted tiene una PMF \\(\\vec{s}\\) y una cadena de Markov con una matriz de transición \\(Q\\), entonces \\(s_i q_{ij}=s_jq_{ji}\\) para todos los estados \\(i,j\\) implica que \\(\\vec{s}\\) es estacionario. 13.6 Caminata Aleatoria en una Red Indirecta knitr::include_graphics(“11.png”) Si usted tiene una colección de \\(\\textbf{nodos}\\), de los cuales los pares se pueden conectar con \\(vérticess\\) indirectos, y una cadena de Markov consiste en ir de un nodo actual a un nodo uniformemente aleatorio conectado a este con un vértice, eso es una caminata aleatorio en una red indirecta. La distribución estacionaria de una cadena es proporcional a la secuencia de grado (es la secuencia de grados, donde el grado de un nodo es cuantos vértices están unidos a este). Por ejemplo, la distribución estacionaria de una caminata aleatoria en una red mostrada arriba es proporcional a \\((3,3,2,4,2)\\), y también \\((\\frac{3}{14},\\frac{3}{14},\\frac{3}{14},\\frac{4}{14}, \\frac{2}{14})\\). "],
["distribuciones-continuas.html", "14 Distribuciones Continuas 14.1 Distribución Uniforme 14.2 Distribución Normal 14.3 Distribución Exponencial 14.4 Distribución Gamma 14.5 Distribución Beta 14.6 Distribución Chi-Cuadrado", " 14 Distribuciones Continuas 14.1 Distribución Uniforme Digamos que \\(U\\) se distribuye \\(Unif(a,b)\\). Sabemos lo siguiente: \\(\\textbf{Propiedades de la Uniforme}\\): Para una distribución Uniforme, la probabilidad de un empate en cualquier intervalo dentro del dominio es proporcional al largo del intervalo. Vea \\(\\textit{Universalidad de la Uniforme y Otros Estadísticos}\\) para otras propiedades. \\(\\textbf{Ejemplo:}\\) William tira dardos muy mal, entonces sus dardos se encuentran distribuciones uniformemente en toda la habitación porque es igualmente posible que aparezcan en cualquier lugar. Los dardos de William tienen una distribución Uniforme en la superficie de la habitación. La Uniforme es la única distribución donde la probabilidad de una región específica es proporcional al largo/área/volumen de esa región, y la densidad de ocurrencia en cualquier punto es constante en todo el dominio. 14.2 Distribución Normal Digamos que X se distribuye \\(N(\\mu, \\sigma ^2)\\). Sabemos lo siguiente: \\(\\textbf{Teorema del Límite Central:}\\) La distribución Normal es ubicua gracias al Teorema del Límite Central, el cual dice que la media muestral de v.a.s que son i.i.d. va a aproximar una distribución Normal conforme el tamaño de la muestra crezca, sin importar la distribución inicial. \\(\\textbf{Transformación Escala-Locación:}\\) Siempre que cambiemos de posición una v.a. Normal (agregando una constante) o cambiemos de escala una Normal (multiplicando por una constante), la cambiamos por otro v.a. Normal. Para cualquier \\(X\\)~\\(N(\\mu,\\sigma^2)\\), la podemos transformar en una v.a. \\(N(0,1)\\) utilizando la siguiente transformación: \\(Z=\\frac{X-\\mu}{\\sigma}\\sim N(0,1)\\) \\(\\textbf{Normal Estándar:}\\) La Normal Estándar, \\(Z\\)~\\(N(0,1)\\), tiene media 0 y varianza 1. SU CDF se denota con \\(\\Phi\\). 14.3 Distribución Exponencial Digamos que X se distribuye \\(Expo(\\lambda)\\). Sabemos lo siguiente: \\(\\textbf{Historia:}\\) Usted está sentado en un campo abierto justo antes del amanecer, deseando que los aviones en el cielo de la noche lanzaran estrellas fugaces, porque le serviría mucho un deseo en este momento. Usted sabe que las estrellas fugaces llegan cada 15 minutos en promedio, pero una estrella fugaz no “tiene que” venir solo porque usted espero mucho tiempo. Su tiempo de espera “no tiene memoria”; el tiempo adicional hasta la siguiente estrella fugaz llegue no depende en el tiempo que usted haya esperado. \\(\\textbf{Ejemplo:}\\) El tiempo de espera hasta la siguiente estrella fugaz está distribuido en \\(Expo(4)\\) horas. Aquí \\(\\lambda =4\\) es el \\(\\textbf{parámetro de ritmo/velocidad}\\), dado que las estrellas fugaces llegan a un ritmo de 1 cada \\(1/4\\) horas en promedio. El tiempo esperado hasta la siguiente estrella fugaz es \\(1/\\lambda =1/4\\) horas. \\(\\textbf{Expos rescaladas como Expo(1):}\\) \\(Y\\)\\(Expo(\\lambda) \\rightarrow X=\\lambda Y\\)\\(Expo(1)\\) \\(\\textbf{Sin memoria:}\\) La distribución Exponencial es la única distribución continua sin memoria. Esta propiedad dice que para \\(X\\sim Expo(\\lambda)\\) y números positivos cualquiera \\(s\\) y \\(t\\), \\(P(X&gt;s+t|X&gt;s)=P(X&gt;t)\\) Lo que es equivalente a, \\(X-a|(X&gt;a)\\sim Expo(\\lambda)\\) Por ejemplo, un producto con esperanza de vida \\(Expo(\\lambda)\\) está siempre “como nuevo” (no experimenta desgaste). Dado que el producto ha sobrevivido \\(a\\) años, el tiempo adicional que va a durar sigue siendo \\(Expo(\\lambda)\\). \\(\\textbf{Min de una Expo:}\\) Si tenemos \\(X_i\\)~\\(Expo(\\lambda_i)\\) independientes, entonces \\(min(X_1,...,X_k)\\)~\\(Expo(\\lambda_1+\\lambda_2+...+\\lambda_k)\\). \\(\\textbf{Max de una Expo:}\\) Si tenemos \\(X_i\\)~\\(Expo(\\lambda)\\) i.i.d., entonces \\(max(X_1,...,X_k)\\) tiene la misma distribución que \\(Y_1+Y_2+...+Y_k\\), donde \\(Y_j\\)~\\(Expo(j\\lambda)\\) y las \\(Y_j\\) son independientes. 14.4 Distribución Gamma knitr::include_graphics(“12.png”) Digamos que X se distribuye \\(Gamma(\\alpha,\\lambda)\\). Sabemos lo siguiente: \\(\\textbf{Historia:}\\) Usted está sentado esperando estrellas fugaces, donde el tiempo de espera se distribuye \\(Expo(\\lambda)\\). Quiere ver \\(n\\) estrellas fugaces antes de irse a casa. El tiempo total de espera para la \\(n-ésima\\) estrella fugaz es \\(Gamma(n,\\lambda)\\). \\(\\textbf{Ejemplo:}\\) Usted está en un banco y hay 3 personas delante suyo. El tiempo de atención para cada persona es Exponencial con media de 2 minutos. Solo una persona puede ser atendida a la vez. La distribución del tiempo de espera hasta que sea su turno es \\(Gamma(3,\\frac{1}{2})\\). 14.5 Distribución Beta knitr::include_graphics(“13.png”) \\(\\textbf{Previa Conjugada para la Binomial: }\\) En la aproximación Bayesiana a la Estadística, los parámetros son vistos como variables aleatorias para reflejar la incertidumbre. La \\(\\textit{previa}\\) para un parámetro es su distribución antes de observar los datos. La \\(\\textit{posterior}\\) es la distribución para el parámetro después de observar los datos. La distribución Beta es una previa \\(\\textit{conjugada}\\) para la Binomial porque su usted tiene una previa Beta para \\(p\\) en una Binomial, entonces la distribución posterior también se distribuye Beta. Considere el siguiente modelo de dos niveles: \\(X|p\\sim Bin(n,p)\\) \\(p\\)~\\(Beta(a,b)\\) Entonces después de observar \\(X=x\\), obtenemos la distribución posterior \\(p|(X=x)\\)~\\(Beta(a+x, b+n-x)\\) \\(\\textbf{Estadísticos de Orden de la Uniforme:}\\) Ver \\(\\textit{Estadísticos de Orden}\\). \\(\\textbf{Relación Beta-Gamma:}\\) Si \\(X\\)~\\(Gamma(\\alpha, \\lambda)\\), \\(Y\\)~\\(Gamma(b,\\lambda)\\), con \\(X \\perp Y\\) entonces: \\(\\bullet\\) \\(\\frac{X}{X+Y}\\sim Beta(a,b)\\) \\(\\bullet\\) \\(X + Y \\perp \\frac{X}{X+Y}\\) 14.6 Distribución Chi-Cuadrado Digamos que X se distribuye \\(X^2\\). Sabemos lo siguiente: \\(\\textbf{Historia:}\\) Una \\(Chi-Cuadrado(n)\\) es la suma de v.a. Normales Estándar al cuadrado. \\(\\textbf{Propiedades y Representaciones:}\\) X está distribuida como \\(Z^2_1+Z^2_2+...+Z^2_n\\) para \\(Z_i \\sim N(0,1)\\) i.i.d. \\(X\\sim Gamma(n/2,1/2)\\) "],
["discretas.html", "15 Distribuciones Discretas 15.1 Distribuciones para cuatro esquemas de muestreo 15.2 Distribución de Bernoulli 15.3 Distribución Binomial 15.4 Distribución Geométrica 15.5 Distribución del Primer Éxito 15.6 Distribución Binomial Negativa 15.7 Distribución Hipergeométrica 15.8 Distribución de Poisson", " 15 Distribuciones Discretas 15.1 Distribuciones para cuatro esquemas de muestreo Con Reemplazo Sin Reemplazo Número finito de ensayos (n) Binomial (Bern si n=1) HGeom Intentar hasta r éxitos NBin (Geom si r=1) HGeomN 15.2 Distribución de Bernoulli La distribución de Bernoulli es el caso más simple de la distribución Binomial, donde solo se tiene un ensayo (n=1). Digamos que X se distribuye \\(Bern(p)\\). Sabemos lo siguiente: \\(\\textbf{Historia:}\\) Un ensayo es realizado con la probabilidad \\(p\\) de “éxito”, y X es el indicador de ese éxito: 1 significa éxito y 0 fracaso. \\(\\textbf{Ejemplo:}\\) Sea X el indicado de Caras al tirar una moneda justa. Entonces \\(X \\sim Bern(\\frac{1}{2})\\). También, \\(1 - X \\sim Bern(\\frac{1}{2})\\) es el indicador de Cruz. 15.3 Distribución Binomial knitr::include_graphics(“14.png”) Digamos que X se distribuye \\(Bin(n,p)\\). Sabemos lo siguiente: \\(\\textbf{Historia:}\\) X es el numero de “éxitos” que vamos a lograr en n ensayos independientes, donde cada ensayo es o un éxito o un fracaso., cada uno con probabilidad \\(p\\) de éxito. También podemos escribir X como la suma de variables aleatorias independientes Bern(p). Sea \\(X \\sim Bin(n,p)\\) y \\(X_j \\sim Bern(p)\\), donde todas las Bernoullis son independientes. Entonces \\(X = X_1 + X_2 + X_3 + ... + X_n\\) \\(Ejemplo:\\) Si Jeremy Lin hace 10 tiros libres y cada uno tiene, independientemente, una probabilidad de entrar de \\(\\frac{3}{4}\\), entonces el número de tiros libres que logra se distribuye \\(Bin(10, \\frac{3}{4})\\). \\(\\textbf{Propiedades:}\\) Sea \\(X \\sim Bin(n,p)\\), \\(Y \\sim Bin(m,p)\\) con \\(X \\perp Y\\). \\(\\bullet \\textbf{Redefiniendo el exito:} \\text{n-X} \\sim Bin(n,1-p)\\) \\(\\bullet \\textbf{Suma:}X+Y \\sim Bin(n+m,p)\\) \\(\\bullet \\textbf{Condicional:}X|(X+Y=r)\\sim HGeom(n,m,r)\\) \\(\\bullet \\textbf{Relacion Binomial-Poisson:} Bin(n,p) \\text{es aproximadamente}\\) \\(Pois(\\lambda)\\) si p es pequeña. \\(\\bullet \\textbf{Relacion Binomial-Normal:}Bin(n,p)\\) es aproximadamente \\(N(np,np(1-p))\\) si \\(n\\) es grande y \\(p\\) no esta cerca de 0 o 1. 15.4 Distribución Geométrica Digamos que X se distribuye \\(Geom(p)\\). Sabemos lo siguiente: \\(\\textbf{Historia:}\\) X es el numero de “fracasos” que vamos a obtener antes de obtener nuestro primer éxito. Nuestros éxitos tienen probabilidad \\(p\\). \\(\\textbf{Ejemplo:}\\) Si cada pokebola que tiramos tiene una probabilidad \\(\\frac{1}{10}\\) de atrapar a Mew, el número de pokebolas fallidas se distribuye \\(Geom(\\frac{1}{10})\\). 15.5 Distribución del Primer Éxito Es equivalente a la distribución Geométrica, excepto que incluye el primer éxito en la cuenta. Esto es una unidad mas que el número de fracasos. Si \\(X \\sim FS(p)\\) entonces \\(E(X)=1/p\\). 15.6 Distribución Binomial Negativa Digamos que X se distribuye \\(NBin(r,p)\\). Sabemos lo siguiente: \\(\\textbf{Historia:}\\) X es el número de “fracasos” que tenemos antes de obtener nuestro \\(r-ésimo\\) éxito. Nuestros éxitos tiene probabilidad p. \\(\\textbf{Ejemplo:}\\) El Impactrueno tiene una precisión de 60% y puede hacer desmayar a un Raticate salvaje en 3 golpes. El número da fallos antes de que Pikachu logre derrotar a Raticate con un Impactrueno esta distribuido \\(NBin(3,0.6)\\). 15.7 Distribución Hipergeométrica Digamos que X se distribuye \\(HGeom(w,b,n)\\). Sabemos lo siguiente: \\(\\textbf{Historia:}\\) En una población de \\(w\\) objetos deseados y \\(b\\) objetos no deseados, X es el número de “éxitos” que vamos a tener al sacar \\(n\\) objetos, sin reemplazo. Sacar los \\(n\\) objetos se asume que es una \\(\\textbf{muestra simple al azar}\\) (todos los \\(n\\) objetos son igual de probables). \\(\\textbf{Ejemplo:}\\) Aquí se presentan algunos HGeom ejemplos: \\(\\bullet\\) Digamos que solo tenemos \\(b\\) Weedles (fallos) y \\(w\\) Pikachus (éxitos) en el Bosque Viridian. Nos encontramos \\(n\\) Pokemones en el bosque, y X es el número de Pikachus que nos encontramos. \\(\\bullet\\) El número de Aces en una mano de 5 cartas. \\(\\bullet\\) Si usted tiene \\(w\\) bolas blancas y \\(b\\) bolas negras, y saca \\(n\\) bolas. Va a sacar X bolas blancas. \\(\\bullet\\) Si usted tiene \\(w\\) bolas blancas y \\(b\\) bolas negras y saca \\(n\\) bolas sin reemplazo. El número de bolas blancas en su muestra es \\(HGeom(w,b,n)\\); el número de bolas negras es \\(HGeom(b,w,n)\\). \\(\\bullet \\textbf{Captura y Recaptura:}\\) Un bosque tiene \\(N\\) alces, usted captura \\(n\\) de ellos, los marca y luego los libera. Luego vuelve a recapturar una nueva muestra de tamaño \\(m\\). ¿Cuantos alces marcados hay en la nueva muestra \\(HGeom(n,N-n,m)\\). 15.8 Distribución de Poisson Digamos que X se distribuye \\(Poi(\\lambda)\\). Sabemos lo siguiente: \\(\\textbf{Historia:}\\) Hay eventos raros (eventos con bajas probabilidades) que ocurren de muchas formas (altas posibilidades de ocurrencia) a un ritmo de \\(\\lambda\\) ocurrencias por unidad de espacio o tiempo. El número de eventos que ocurren en esa unidad de espacio o tiempo es X. \\(\\textbf{Ejemplo:}\\) Una intersección ocupada tiene un promedio de 32 accidentes por mes. Dado que un accidente es un evento de baja probabilidad que puede pasar de muchas formas, es razonable modelar el número de accidentes en un mes en esa intersección como una \\(Pois(2)\\). Entonces el número de accidentes que pasan en dos meses en esa intersección se distribuye \\(Poi(4)\\). \\(\\textbf{Propiedades:}\\) Sea \\(X \\sim Pois(\\lambda_1)\\) y \\(Y \\sim Pois(\\lambda_2)\\), con \\(X \\perp Y\\). \\(\\textbf{Suma:}X+Y \\sim Pois(\\lambda_1 + \\lambda_2)\\) \\(\\textbf{Condicional:} X|(X+Y=nn)\\sim Bin \\Big(n, \\frac{\\lambda_1}{\\lambda_1 + \\lambda_2} \\Big)\\) \\(\\textbf{Huevo de gallina:}\\) Si hay \\(Z \\sim Pois(\\lambda)\\) ítems y solo aceptamos aleatoriamente e independientemente cada ítem con probabilidad \\(p\\), entonces el número de ítems aceptado \\(Z_1 \\sim Pois(\\lambda p)\\), y el número de ítems rechazados \\(Z_2 \\sim Pois(\\lambda (1-p))\\) y \\(Z_1 \\perp Z_2\\). "],
["multi.html", "16 Distribuciones Multivariadas 16.1 Distribución Multinomial 16.2 Distribución Uniforme Multivariada 16.3 Distribución Normal Multivariada (NMV)", " 16 Distribuciones Multivariadas 16.1 Distribución Multinomial Digamos que el vector \\(\\vec{X}=(X_1, X_2,X_3,...,X_k)\\sim Mult_k(n,\\vec{p})\\) donde \\(\\vec{p}=(p_1,p_2,...,p_k)\\). \\(\\textbf{Historia:}\\) Tenemos \\(n\\) ítems, los cuales pueden caer en cualquiera de las \\(k\\) canastas independientemente con probabilidades \\(\\vec{p}=(p_1,p_2,...,p_k)\\). \\(\\textbf{Ejemplo:}\\) Asumamos que cada año 100 estudiantes en el Universo de Harry Potter son aleatoria e independientemente asignados a una de las cuatro casas con igual probabilidad. El número de personas en cada una de las casa se distribuye \\(Mult_k(100, \\vec{p})\\), donde \\(\\vec{p}=c(0.25,0.25,0.25,0.25).\\) Note que \\(X_1 + X_2 + ... + X_4=100\\) y que son dependientes. \\(\\textbf{PMF Conjunta:}\\) Para \\(n=n_1+n_2+...+n_k\\), \\(P(\\vec{X}=\\vec{n})=\\frac{n!}{n_1!n_2!...n_k!}p_1^{n_1}p_2^{n_2}...p_k^{n_k}\\) \\(\\textbf{PMF Marginal, Agrupamiento y Condicionales:}\\) Marginalmente, \\(X_i \\sim Bin(n,p)\\) ya que podemos definir como “éxito” como la media de la categoría \\(i\\). Si agrupa múltiples categorías juntas en una Multinomial, entonces todavía es Multinomial. Por ejemplo, \\(X_i + X_j \\sim Bin(n, p_i + p_j)\\) para \\(i \\ne j\\) ya que podemos definir como “éxito” la media de la categoría \\(i\\) o \\(j\\). Similarmente si \\(k=6\\) y agrupamos las categorías 1-2 y agrupamos las categorías 3-5, entonces \\((X_1 + X_2, X_3 + X_4, X_6) \\sim Mult_3(n, (p_1+p_2, p_3+p_4+p)_5, p_6))\\) Condicionando con alguna \\(X_j\\) también obtenemos una Multinomial: \\(X_1,...,X_{k-1}|X_k = nk \\sim Mult_{k-1}\\Big(n-n_k, \\Big(\\frac{p_1}{1-p_k},...,\\frac{p_{k-1}}{1-p_k}\\Big) \\Big)\\) \\(\\textbf{Varianza y Covarianzas:}\\) Tenemos \\(X_i \\sim Bin(n,p_i)\\) marginalmente, entonces \\(Var(X_i)=np_i(1-p_i)\\). También, \\(Cov(X_i, X_j)=-np_ip_j\\) para \\(i \\ne j\\). 16.2 Distribución Uniforme Multivariada Vea la distribución Uniforme univariada para historias y ejemplos. Para la Uniforme 2D en una región cualquiera, la probabilidad es proporcional a su área. Todos los puntos en el dominio tiene igual densidad, de valor \\(\\frac{1}{\\text{área de la región}}\\). Para la Uniforme 3D, la probabilidad es proporcional a su volumen. 16.3 Distribución Normal Multivariada (NMV) Un vector \\(\\vec{X}=(X_1, X_2, ..., X_k)\\) es una Normal Multivariada si cada combinación lineal esta Normalmente distribuida, e.j. \\(t_1X_1 + t_2 X_2 + ...+t_kX_k\\) es Normal para cualquier constantes \\(t_1, t_2,...,t_k\\). Los parámetros de la Normal Multivariada son el \\(\\textbf{vector de medias}\\) \\(\\vec{\\mu}=(\\mu_1 \\mu_2,...,\\mu_k)\\) y la \\(\\textbf{matriz de covarianza}\\) donde la entrada \\((i,j)\\) es \\(Cov(X_i,X_j)\\). \\(\\textbf{Propiedades:}\\) La Normal Multivariada tiene la siguientes propiedades \\(\\bullet\\) Cualquier subvector es también NMV \\(\\bullet\\) Si dos elementos cualquiera dentro de una NMV no están correlacionados, entonces son independientes. \\(\\bullet\\) La PDF conjunta de una Normal Bivariada \\((X,Y)\\) con distribuciones marginales \\(N(0,1)\\) y correlación \\(\\rho \\in (-1,1)\\) es \\(f_{X,Y}(x,y)= \\frac{1}{2\\pi \\gamma}exp \\Big(-\\frac{1}{2\\gamma^2}(x^2+y^2-2\\rho xy) \\Big)\\), con \\(\\gamma = \\sqrt{1-\\rho ^2}.\\) "],
["props.html", "17 Propiedades de las Distribuciones 17.1 CDFs Importantes 17.2 Convoluciones de Variables Aleatorias 17.3 Casos Especiales 17.4 Desigualdades", " 17 Propiedades de las Distribuciones 17.1 CDFs Importantes \\(\\textbf{Normal Estandar}=\\Phi\\) \\(\\textbf{Exponencial}(\\lambda)= F(x)=1-e^{-\\lambda x}\\), para \\(x \\in (0, \\infty)\\) \\(\\textbf{Uniforme(0,1)}=F(x)=x\\) para \\(x \\in (0,1)\\) 17.2 Convoluciones de Variables Aleatorias La convolución de \\(n\\) variables aleatorias es simplemente su suma. Para los siguientes resultados, X y Y son \\(\\textit{independientes}\\). \\(X \\sim Pois(\\lambda_1), Y\\sim Pois(\\lambda_2) \\longrightarrow X+Y \\sim Pois(\\lambda_1 + \\lambda_2)\\) \\(X \\sim Bin(n_1, p), Y \\sim Bin(n_2,p) \\longrightarrow X+Y \\sim Bin(n_1+n_2, p)\\). \\(Bin(n,p)\\) puede pensarse como la suma de v.a. i.i.d. Bern(p) \\(X \\sim Gamma(\\alpha _1, \\lambda), Y \\sim Gamma(\\alpha_2, \\lambda) \\longrightarrow X+Y \\sim Gamma(\\alpha _1 + \\alpha _2, \\lambda)\\). \\(Gamma(n,\\lambda)\\) con \\(n\\) entero puede pensarse como la suma de v.a. i.i.d. \\(Expo(\\lambda)\\). \\(X\\sim NBin(r_1, p), Y \\sim NBin(r_2, p) \\longrightarrow X+Y \\sim NBin(r_1+r_2,p)\\). \\(NBin(r,p)\\) puede pensarse como la suma de v.a. i.i.d. \\(Geom(p)\\). \\(X \\sim N(\\mu_1, \\sigma_1^2), Y\\sim N(\\mu_2, \\sigma_2^2) \\longrightarrow X+Y\\sim N(\\mu_1+\\mu_2, \\sigma_1 ^2+\\sigma_2 ^2)\\) 17.3 Casos Especiales 1.\\(Bin(1,p)\\sim Bern(p)\\) 2.\\(Beta(1,1) \\sim Unif(0,1)\\) 3.\\(Gamma(1,\\lambda)\\sim Expo(\\lambda)\\) 4.\\(X^2_n\\sim Gamma(\\frac{n}{2}, \\frac{1}{2})\\) 5.\\(NBin(1,p)\\sim Geom(p)\\) 17.4 Desigualdades 1.\\(\\textbf{Cauchy-Schwarz}\\) \\(|E(XY)| \\le \\sqrt{E(X^2)E(Y^2)}\\) 2.\\(\\tetxbf{Markov}\\) \\(P(X \\ge a) \\le \\frac{E|X|}{a}\\) para a &gt; 0 3.\\(\\textbf{Chebyshev}\\) \\(P(|X-\\mu|\\ge a) \\le \\frac{\\sigma^2}{\\sigma^2}\\) para \\(E(X)=\\mu\\), \\(Var(X)=\\sigma^2\\) 4.\\(\\textbf{Jensen}\\) \\(E(g(X)) \\ge g(E(X))\\) para \\(g\\) convexa; al revés si \\(g\\) es cóncava. "],
["formulas.html", "18 Fórmulas 18.1 Series Geométricas 18.2 Función Exponencial 18.3 Integrales Gamma y Beta 18.4 Aproximación de Euler a las Sumas Armónicas 18.5 Aproximación de Stirling a los Factoriales", " 18 Fórmulas 18.1 Series Geométricas \\(1 + r + r^2 +...+r^{n-1}=\\displaystyle\\sum_{n=0}^{\\infty}r^k=\\frac{1-r^n}{1-r}\\) \\(1+r+r^2+...=\\frac{1}{1-r}\\) si \\(|r|&lt;1\\) 18.2 Función Exponencial \\(e^x = \\displaystyle\\sum_{n=0}^{\\infty}\\frac{x^n}{n!}=1+x+\\frac{x^2}{2!}+\\frac{x^3}{3!}+...=\\lim_{n \\rightarrow \\infty} \\Big(1+\\frac{x}{n} \\Big)^n\\) 18.3 Integrales Gamma y Beta A veces se pueden resolver integrales que parecen muy complicadas completando una integral Gamma o Beta: \\(\\displaystyle\\int_{0}^{\\infty} x^{t-1}e^{-x}dx= \\Gamma(t)\\) \\(\\int_{0}^{1} x^{a-1}(1-x)^{b-1}dx=\\frac{\\Gamma(a) \\Gamma(b)}{\\Gamma(a+b)}\\) También,\\(\\Gamma(a+1)=a\\Gamma(a)\\) y \\(\\Gamma(n)=(n-1)!\\) si \\(n\\) es un entero positivo. 18.4 Aproximación de Euler a las Sumas Armónicas \\(1+\\frac{1}{2}+\\frac{1}{3}+...+\\frac{1}{n} \\approx log n+ 0.577...\\) 18.5 Aproximación de Stirling a los Factoriales \\(n! \\approx \\sqrt{2 \\pi n}(\\frac{n}{e})^n\\) "],
["definiciones.html", "19 Definiciones Varias", " 19 Definiciones Varias \\(\\textbf{Medianas y Cuantiles:}\\) Digamos que X tiene CDF \\(F\\). Entonces X tiene una mediana \\(m\\) si \\(F(m) \\ge 0.5\\) y \\(P(X \\ge m) \\ge0.5\\). Para X continua, \\(m\\) satisface \\(F(m)=1/2\\). En general, el \\(a-esimo\\) cuantil de X es mín{\\(x:F(x)\\ge a\\)}; la mediana es el caso \\(a=1/2\\). \\(\\textbf{log:}\\) Los estadísticos (as) generalmente usan log para referirse a logaritmo natural (base \\(e\\)). \\(\\textbf{v.a. i.i.d: }\\) Variables aleatorias independientes e idénticamente distribuidas. \\(\\textbf{CDF:}\\) Función de distribución, por sus siglas en Inglés \\(\\textbf{PMF:}\\) Función de probabilidad, por sus siglas en Inglés \\(\\textbf{PDF:}\\) Función de densidad, por sus siglas en Inglés "],
["ejemplos.html", "20 Ejemplos 20.1 Calculando Probabilidades 20.2 Linealidad e Indicadores (1) 20.3 Linealidad y Primeros Éxitos 20.4 Ordenamientos de variables aleatorias i.i.d. 20.5 Expectativa de una Hipergeométrica Negativa 20.6 Mínimo y Máximo de VAs 20.7 Emparejando patrones con la serie de Taylor 20.8 La Ley de Adán y Eva 20.9 FGM - Encontrando Momentos 20.10 Cadenas de Markov (1) 20.11 Cadenas de Markov (2)", " 20 Ejemplos Contribuciones de Sebastian Chiu 20.1 Calculando Probabilidades Un libro tiene \\(n\\) errores de escritura, los cuales están dispersos en las \\(n\\) páginas independientemente. Usted escoge una página aleatoria. ¿Cuál es la probabilidad de que no tenga errores. \\(\\textbf{Respuesta:}\\) Hay una probabilidad de \\((1-\\frac{1}{n})\\) de que cualquier errores específico no este en la página, y entonces hay una probabilidad \\(\\Big(1-\\frac{1}{n} \\Big)^n\\) de que no haya ningún error en nuestra página. Para n grande, esto es aproximadamente \\(e^{-1} = 1/e\\). 20.2 Linealidad e Indicadores (1) \\(\\textit{Este problema es comúnmente conocido como el}\\) \\(\\textbf{problema de emparejamiento}\\). Hay \\(n\\) personas en una fiesta, cada uno con un sombrero. Al final de la fiesta, se tienen que ir con un sombrero al azar. ¿Cuál es el número esperado de personas que se vayan con el sombrero correcto? \\(\\textbf{Respuesta:}\\) Cada sombrero tiene una probabilidad de \\(1/n\\) de irse con la persona correcta. Por linealidad, el promedio de sombreros que se van con sus dueños es \\(n(1/n)=1\\). 20.3 Linealidad y Primeros Éxitos \\(textbf{Este problema es comúnmente conocido como el}\\) \\(\\textbf{problema del coleccionista de cupones.}\\) Hay \\(n\\) tipos de cupones. En cada sorteo, usted obtiene un tipo de cupón uniformemente distribuido. ¿Cuál es número de cupones necesarios hasta que se complete el juego? \\(\\textbf{Respuesta:}\\) Sea N el numero de cupones necesarios; queremos \\(E(N)\\). Sea \\(N=N_1+...+N_n\\), donde \\(N_1\\) es el sorteo donde se obtiene nuestro primer cupón, \\(N_2\\) es el sorteo \\(\\textit{adicional}\\) para obtener nuestro segundo cupón y si sucesivamente. Recordando la historia del Primer Éxito, \\(N_2 \\sim FS((n-)/n)\\) (después de recolectar el primer tipo de cupón, hay una probabilidad de \\((n-1)/n\\) de que usted va a obtener algo nuevo). Similarmente, \\(N_3 \\sim FS((n-2)/n)\\) y \\(N_j \\sim FS((n-j+1)/n)\\). Por linealidad, \\(E(N)=E(N_1)+...+E(N_n)=\\frac{n}{n}+\\frac{n}{n-1}+...+\\frac{n}{1}= n \\displaystyle\\sum_{j=1}^{n} \\frac{1}{j}\\) Esto es aproximadamente \\(n(log(n)+0.577)\\) por la aproximación de Euler. 20.4 Ordenamientos de variables aleatorias i.i.d. Yo llamo 2 UberXs y 3 Lyfts al mismo tiempo. Si los tiempos que duran los carros en llegar a mi son i.i.d., ¿cuál es la probabilidad de que los 3 Lyfts lleguen al mismo tiempo? \\(\\textbf{Respuesta:}\\) Dado que los tiempos de llegada de los cinco carros son i.i.d., los \\(5!\\) ordenamientos de las llegadas son igualmente posibles. Hay \\(3!2!\\) ordenamientos que involucran que los Lyfts lleguen primero, entonces la probabilidad de que los Lyfts lleguen primero es \\(\\frac{3!2!}{5!}=1/10\\). Alternativamente, hay $ 53$ maneras de escoger 3 de los 5 campos para que los Lyfts los ocupen, donde cada una de las opciones es igualmente posibles. En una de esas opciones tiene los 3 Lyfts llegan primero entonces la probabilidad es \\(1/{5 \\choose 3} =1/10\\). 20.5 Expectativa de una Hipergeométrica Negativa ¿Cuál es el número esperado de cartas que usted va a sacar antes de sacar su primer As en un mazo (sin contar el As)? \\(\\textbf{Respuesta:}\\) Considere un carta que no es As. Denote esta como una carta \\(j\\). Sea \\(I_j=1\\) el indicador de que la carta \\(j\\) va a ser elegida primero que el primer As. Note que \\(I_j =1\\) dice que \\(j\\) es antes que los 4 Ases del mazo. La probabilidad de que esto ocurra es \\(1/5\\) por simetría. Sea X el número de cartas que salen entes del primer As. Entonces \\(X=I_1+I_2+...+I_{48}\\), donde cada indicador corresponde a uno de los 48 “no Ases”. Entonces, \\(E(X)=E(I_1)+E(I_2)+...+E(I_{48})=48/5 = 9.6\\) 20.6 Mínimo y Máximo de VAs ¿Cuál es la CDF del máximo de \\(n\\) v.a. \\(Unif(0,1)\\) independientes? \\(\\textbf{Respuesta:}\\) Note que para las v.a \\(X_1, X_2,...,X_n\\), \\(P(min(X_1,X_2,...,X_n)\\ge a)=P(X_1 \\ge a, X_2 \\ge a,..., X_n \\ge a)\\) Similarmente \\(P(min(X_1,X_2,...,X_n)\\le a)=P(X_1 \\le a, X_2 \\le a,..., X_n \\le a)\\) Usaremos este principio para encontrar la CDF de \\(U_{(n)}\\), donde \\(U_{(n)}=max(U_1, U_2,...,U_n)\\) y las \\(U_i \\sim Unif(0,1)\\) son i.i.d. \\(P(max(U_1,U_2,...,U_n)\\le a)=P(U_1 \\le a, U_2\\le a,..., U_n \\le a)\\) \\(=P(U_1 \\le a)P(U_2 \\le a)...P(U_n \\le a)\\) \\(=a^n\\) Para \\(0&lt;a&lt;1\\) (y la CDF es 0 para \\(a\\le 0\\) y para \\(a \\ge 1\\)). 20.7 Emparejando patrones con la serie de Taylor Para \\(X \\sim Pois(\\lambda)\\), encuentre \\(E\\Big(\\frac{1}{X+1} \\Big)\\). \\(\\textbf{Respuesta:}\\) Por LOTUS, \\(E\\Big(\\frac{1}{X+1} \\Big)= \\displaystyle\\sum_{k=0}^{\\infty} \\frac{1}{k+1} \\frac{e^{-\\lambda} \\lambda^k}{k!}=\\frac{e^{-\\lambda}}{\\lambda} \\displaystyle\\sum_{k=0}^{\\infty} \\frac{\\lambda^{k+1}}{(k+1)!}=\\frac{e^{-\\lambda}}{\\lambda}(e^{\\lambda} -1)\\) 20.8 La Ley de Adán y Eva A William le gusta mucho resolver rápidamente Cubos Rubik. Pero es muy malo haciéndolo, entonces a veces falla. En un día cualquiera, William va a intentar \\(N \\sim Geom(s)\\) Cubos Rubik. Suponga que cada vez, William tiene la probabilidad \\(p\\) de resolver el cubo (independiente). Sea \\(T\\) el número de cubos Rubik que resuelve durante el día. Encuentre la media y la varianza de \\(T\\). \\(\\textbf{Respuesta:}\\) Note que \\(T|N \\sim Bin(N,p)\\). Entonces por la Ley de Adán, \\(E(T)=E(E(T|N))=E(Np)=\\frac{p(1-s)}{s}\\) Similarmente, por la Ley de Eva, tenemos que \\(Var(T)=E(Var(T|N))+Var(E(E|N))=E(Np(1-p))+Var(Np)\\) \\(=\\frac{p(1-p)(1-s)}{s}+\\frac{p^2(1-s)}{s^2}=\\frac{p(1-s)(p+s(1-p))}{s^2}\\) 20.9 FGM - Encontrando Momentos Encuentre \\(E(X^3)\\) para \\(Expo(\\lambda)\\) usando la FGM de X. \\(\\textbf{Respuesta:}\\) La FGM de una \\(Expo(\\lambda)\\) es \\(M(t)=\\frac{\\lambda}{\\lambda-t}\\). Para obtener el tercer momento, podemos tomar la tercer derivada de la FGM y evaluar en \\(t=0\\): \\(E(X^3)=\\frac{6}{\\lambda^3}\\) Pero una mejor forma de usar la FGM es para reconocer patrones: note que \\(M(t)\\) luce como si viniera de una serie geométrica: \\(\\frac{1}{1-\\frac{t}{\\lambda}}=\\displaystyle\\sum_{n=0}^{\\infty} \\Big(\\frac{t}{\\lambda} \\Big)^n = \\displaystyle\\sum_{n=0}^{\\infty}\\frac{n!}{\\lambda ^n}\\frac{t^n}{n!}\\) El coeficiente de \\(\\frac{t^n}{n!}\\) aquí es el \\(n-esimo\\) momento de X, entonces tenemos \\(E(X^n)=\\frac{n!}{\\lambda^n}\\) para todos los enteros no negativos \\(n\\). 20.10 Cadenas de Markov (1) Suponga que \\(X_n\\) es una cadena de Markov de dos estados con la matriz de transición \\(0\\) \\(1\\) $Q= \\[\\begin{matrix} 0 \\\\ 1 \\end{matrix} \\begin{pmatrix} 1-\\alpha &amp; \\alpha \\\\ \\beta &amp; 1-\\beta \\end{pmatrix}\\] $ Encuentre la distribución estacionaria \\(\\vec{s}=(s_0,s_1)\\) de \\(X_n\\) resolviendo \\(\\vec{s}Q=\\vec{s}\\), y muestre que la cadena es reversible con respecto a \\(\\vec{s}\\). \\(\\textbf{Respuesta:}\\) La ecuación \\(\\vec{s}Q=\\vec{s}\\) dice que \\(s_0 = s_0(1-\\alpha)+s_1\\beta\\) y \\(s_1=s_0(\\alpha)+s_0(1-\\beta)\\) Resolviendo el sistema de ecuaciones obtenemos \\(\\vec{s}=\\Big(\\frac{\\beta}{\\alpha + \\beta}, \\frac{\\alpha}{\\alpha + \\beta}\\) Para mostrar que la cadena es reversible con respecto a \\(\\vec{s}\\), debemos mostrar \\(s_iq_{ij}=s_j q_{ji}\\) para todo \\(i,j\\). Esto se hace mostrando que \\(s_0 q_{01}=s_1q_{10}\\). Y de hecho, \\(s_0q_{01}=\\frac{\\alpha \\beta }{\\alpha + \\beta}=s_1q_{10}\\) 20.11 Cadenas de Markov (2) William y Sebastian están jugando un juego modificado de Catan, donde en cada turno mueven aleatoriamente un ladrón (el cual empieza en el cuadro del centro) a uno de los hexágonos adyacentes. knitr::include_graphics(“15.png”) ¿Esta cadena de Markov es irreducible? ¿Es aperiódica? \\(\\textbf{Respuesta:}\\) Si ambas. La cadena es irreducible porque puede ir de un lugar a cualquier otro. La cadena también es aperiódica porque el ladrón puede devolverse la casilla en 2,3,4,5,… pasos, y la GCD de esos numero es 1. ¿Cuál es la distribución estacionaria de esta cadena de Markov? \\(\\textbf{Respuesta:}\\) Como esto es una caminata aleatoria en un gráfico sin dirección, la distribución estacionaria es proporcional a la secuencia de grado. El grado para las piezas de la esquina es 3, el grado para las piezas de la orilla es 4 y el grado para las piezas del centro es 6. Para normalizar esta secuencia, la dividimos por la suma. La suma de los grados es \\(6(3) + 6(4) + 7(6) = 84\\). Entonces la probabilidad estacionaria de estar en una esquina es 3/84=1/28%, en la orilla \\(4/84=/21\\) y en el centro \\(6/84=1/14\\). ¿Cuál es la fracción de tiempo que va a estar el ladrón en la pieza del medio en este juego, en el largo plazo? \\(\\textbf{Respuesta:}\\) Por lo anterior: 1/14. ¿Cuál es el número esperado de pasos que se necesitarán para que el ladrón regrese a la pieza del centro? \\(\\textbf{Respuesta:}\\) Como esta cadena es irreducible y aperiódica, para obtener el tiempo esperado solo tenemos que invertir la probabilidad estacionaria. Entonces, en promedio, se necesitaran 4 turnos para que el ladrón regrese a la pieza del centro. "],
["estrategias.html", "21 Estrategias de Resolución de Problemas", " 21 Estrategias de Resolución de Problemas Contribuciones de Jessy Hwang, Yuan Jiang y Yuqi Hou \\(\\textbf{Para empezar.}\\) Empiece \\(\\textit{definiendo los eventos relevantes y las variables aleatorias}\\)(“Sea Y el evento donde escojo la moneda justa”; “Sea X el numero de éxitos”). Una noción clara es importante para lograr pensar con claridad. Luego decida que es lo que debe encontrar, en términos de su notación (“Quiero encontrar \\(P(X=3|A)\\)”). Piense qué tipo de objeto debería ser su respuesta (un número, variable aleatoria, PMF, PDF, etc.) y en términos de que debería estar. \\(\\textit{Intente casos simples y extremos.}\\) Para convertir un experimento abstracto en algo más concreto, intente \\(\\textit{dibujar una imagen}\\) o inventar números que podrían haber sucedido. Reconocimiento de patrones: ¿la estructura del problema se parece a algo que ha visto antes? \\(\\textbf{Calcular la probabilidad de un evento.}\\) Use los principios de conteo si la definición de probabilidad simple aplica. ¿Es más fácil encontrar la probabilidad del complemento? Busque simetrías. Busque algo que pueda condicionar y luego utilice la Regla de Bayes o la Ley de la Probabilidad Total?. \\(\\textbf{Encontrar la distribucion de una variable aleatoria.}\\) Primero asegúrese de que necesita la distribución completa y no solo la media (vea el siguiente ítem). Revise el \\(\\textit{dominio}\\) de la variable aleatoria: ¿qué valores puede tomar? Use esto para descartar distribuciones que no se ajusten. ¿Hay algún historia de las distribuciones conocidas que se ajuste a su problema? ¿Puede escribir la variable aleatoria como una función de una v.a. con una distribución conocida, digamos \\(Y=g(X)\\)? \\(\\textbf{Calcular esperanzas.}\\) Si es una distribución conocida, revise la tabla de distribuciones. Si es una función de una v.a. con una distribución conocida, intente usar LOTUS?. Si es el conteo de algo, intente separarlo en el indicador de v.a.s. Si puede condicionar usando algo natural, considere usar la Ley de Adam. \\(\\textbf{Calcular varianzas.}\\) Considere la independencia, las distribuciones conocidas y LOTUS. Si sirve de algo, sepárelo en la suma de indicadores de v.a.s. Si es una suma, use las propiedades de la covarianza. Si puede condicionar usando algo natural, considere la Ley de Eva. \\(\\textbf{Calcular}\\) \\(E(X^2)\\). ¿Ya conoce \\(E(X)\\) o \\(Var(X)\\)? Recuerde \\(Var(X)=E(X^2)-(E(X))^2\\). De otra forma, utilice LOTUS?. \\(\\textbf{Calcular covarianzas.}\\) Use las propiedades de covarianza. Si esta intentando encontrar la covarianza entre dos componentes de una distribución Multinomial \\(X_i,X_j\\), entonces la covarianza es \\(-np_i p_j\\) para \\(i \\ne j\\). \\(\\textbf{Simetria.}\\) Si \\(X_1,...,X_n\\) son i.i.d, considere usar la simetría. \\(\\textbf{Calcular probabilidades de ordenamientos.}\\) Recuerde que todos los \\(n!\\) ordenamientos de variables continuas i.i.d. \\(X_1,...,X_n\\) son igualmente posibles. \\(\\textbf{Determinar independencia.}\\) Hay varias definiciones equivalentes. Piense en casos simples y extremos para ver si puede encontrar un contra ejemplo. \\(\\textbf{Realice una integral compleja.}\\) Si su integral se ve muy compleja, observe si puede escribirla en términos de una PDF conocida (como Gamma o Beta) y use ese hecho para que esa PDF integre a 1. \\(\\textbf{Antes de seguir adelante.}\\) Revise casos simples y extremos, revise si la respuesta parece creíble, revise si hay “equivocaciones comunes”. "],
["equivocaciones.html", "22 Equivocaciones Comunes", " 22 Equivocaciones Comunes Contribuciones de Jessy Hwang \\(\\textbf{No utilice incorrectamente la definición simple de probabilidad.}\\) Cuando conteste “¿cuál es la probabilidad de que en un grupo de 3 personas, ningún par haya nacido en el mismo mes?”, \\(\\textit{no}\\) es correcto tratar a las personas como bolas indistinguibles que se colocan en 12 cajas, ya que eso asume que la lista de meses {Enero, Enero, Enero} es igual de probable que la lista {Enero, Abril, Junio}, aunque la segunda es seis veces mas probable. \\(\\textbf{No confunda incondicional, condicional y probabilidades conjuntas.}\\) Al aplicar \\(P(A|B)=\\frac{P(A|B)P(A)}{P(B)}\\) \\(\\textit{no}\\) es correcto decir “P(B) = 1 porque B ya ocurrió”; P(B) es la probabilidad \\(\\textit{previa}\\) de B. No confunda P(A|B) con P(A,B). \\(\\textbf{No asuma independencia sin justificación.}\\) En el problema de emparejamiento, la probabilidad de que la carta 1 sea emparejada y la carta 2 también no es \\(1/n^2\\). La Binomial y la Hipergeométrica son comúnmente confundidas; los ensayos son independientes en la historia Binomial y dependientes en la historia Hipergeométrica. \\(\\textbf{No olvide hacer controles de cordura.}\\) Las probabilidades deben estar entre 0 y 1. Las Varianzas deben ser \\(\\ge 0\\). Los dominios deben tener sentido. Las PMFs deben sumar 1. Las PDFs deben integrar a 1. \\(\\textbf{No confunda variables aleatorias, números y eventos.}\\) Sea X una v.a. Entonces \\(g(X)\\) es una v.a. para cualquier función g. En particular \\(X^2\\), \\(|X|\\), \\(F(X)\\), y \\(I_{X&gt;3}\\) son v.a.s. \\(P(X^2&lt;X|X\\ge0), E(X), Var(X)\\) y \\(g(E(X))\\) son números. \\(X=2\\) y \\(F(X) \\ge -1\\) son eventos. No tiene sentido escribir \\(\\int_{-\\infty}^{\\infty}F(X)dx\\), porque \\(F(X)\\) es una variable aleatoria. No tiene sentido escribir \\(P(X)\\), porque \\(X\\) no es un evento. \\(\\textbf{No confunda una variable aleatoria con su distribución.}\\) Para obtener la PDF de \\(X^2\\) no se puede nada más hacer el cuadrado de la PDF de X. La forma correcta es usar transformaciones. Para obtener la PDF de \\(X+Y\\) no puede nada mas sumar la PDF de X y la PDF de Y. La forma correcta es realizar una convolusión. \\(\\textbf{No extraiga funciones no lineales de esperanzas.}\\) \\(E(g(X))\\) no es lo mismo que \\(g(E(X))\\) en general. La paradoja de San Petersburgo es un caso extremo. También puede ver la desigualdad de Jensen. La forma correcta de encontrar \\(E(g(X))\\) es usando LOTUS. "],
["r.html", "23 Distribuciones en R", " 23 Distribuciones en R Comando Lo que hace help(distributions) muestra la documentación de las distribuciones dbinom(k,n,p) PMF \\(P(X=k)\\) para \\(X \\sim Bin(n,p)\\) pbinom(x,n,p) CDF \\(P(X\\le x\\) para \\(X \\sim Bin (n,p)\\) qbinom(a,n,p) \\(a-esimo\\) cuantil para \\(X \\sim Bin (n,p)\\) rbinom(r,n,p) vector de \\(r\\) i.i.d. para v.a. \\(Bin (n,p)\\) dgeom(k,p) PMF \\(P(X=k)\\) para \\(X \\sim Geom(p)\\) dhyper(k,w,b,n) PMF \\(P(X=k)\\) para \\(X \\sim HGeom(w,b,n)\\) dnbinom(k,r,p) PMF \\(P(X=k)\\) para \\(X \\sim NBin(r,p)\\) dpois(k,r) PMF \\(P(X=k)\\) para \\(X \\sim Pois(r)\\) dbeta(x,a,b) PDF \\(f(x)\\) para \\(X \\sim Beta(a,b)\\) dchisq(x,n) PDF \\(f(x)\\) para \\(X \\sim X^2_n\\) dexp(x,b) PDF \\(f(x)\\) para \\(X \\sim Expo(b)\\) dgamma(x,a,r) PDF \\(f(x)\\) para \\(X \\sim Gamma(a,r)\\) dlnorm(x,m,s) PDF \\(f(x)\\) para \\(X \\sim LN(m,s^2)\\) dnorm(x,m,s) PDF \\(f(x)\\) para \\(X \\sim N(m,s^2)\\) dt(x,n) PDF \\(f(x)\\) para \\(X \\sim t_n\\) dunif(x,a,b) PDF \\(f(x)\\) para \\(X \\sim Unif(a,b)\\) La tabla anterior da comandos de R para trabajar con distribuciones conocidas. Comandos análogos a \\(pbinom,qbinom\\) y \\(rbinom\\) funcionan para las otras distribuciones de la tabla. Por ejemplo, \\(pnorm, qnorm\\) y \\(rnorm\\) pueden usarse para obtener la CDF, cuantiles y generación aleatoria para una Normal. Para la Multinomial, \\(dmultinom\\) puede usarse para calcular la PMF conjunta y \\(rmulinom\\) para generar vectores aleatorios. Para la Normal Multivariada, después de instalar y cargar el paquete \\(mvtnorm\\), \\(dmvnorm\\) puede usarse para calcular la PDF conjunta y \\(rmvnorm\\) para generar vectores aleatorios. "],
["fuentes.html", "24 Fuentes Recomendadas", " 24 Fuentes Recomendadas \\(\\bullet\\) Libro Introducción a la Probabilidad (http://bit.ly/introprobability) \\(\\bullet\\) Stat 110 Online (http://stat110.net) \\(\\bullet\\) Blog Stat 110 Quora (https://stat110.quora.com/) \\(\\bullet\\) Quora Probabilidad Preguntas Frecuentes (http://bit.ly/probabilityfaq) \\(\\bullet\\) R Studio (https://www.rstudio.com) \\(\\bullet\\) Archivo LaTeX (github.com/wzchen/probability cheatsheet) \\(\\textit{¡Porfavor compartir con amigos!}\\) "],
["dist.html", "25 Tabla de Distribuciones", " 25 Tabla de Distribuciones Distribución PMF/PDF y Dominio Valor Esperado Varianza FGM Bernoulli. \\(Bern(p)\\) \\(P(X=1)=p\\). \\(P(X=0)=q=1-p\\) \\(p\\) \\(pq\\) \\(q+pe^t\\) Binomial. \\(Bin(n,p)\\) \\(P(X=k)= {n \\choose k}p^kq^{n-k}\\). \\(k \\in\\) {\\(0,1,2,...,n\\)} \\(np\\) \\(npq\\) \\((q+pe^t)^n\\) Geométrica. \\(Geom(p)\\) \\(P(X=k)=q^kp\\). \\(k \\in\\) {\\(0,1,2,...\\)} \\(q/p\\) \\(q/p^2\\) \\(\\frac{p}{1-qe^t}, qe^t &lt;1\\) Binomial Negativa. \\(NBin(r,p)\\) \\(P(X=n)={{r+n-1} \\choose {r-1}} p^rq^n\\). \\(n \\in\\) {\\(0,1,2,...\\)} \\(rq/p\\) \\(rq/p^2\\) \\((\\frac{p}{1-qe^t})^r, qe^t &lt;1\\) Hipergeométrica. \\(HGeom(w,b,n)\\) \\(P(X=k)={w \\choose k}{b \\choose {n-k}}/{{w+b}\\choose n}\\) \\(\\mu =\\frac{nw}{b+w}\\) \\((\\frac{w+b-n}{w+b-1})n\\frac{\\mu}{n}(1-\\frac{\\mu}{n})\\) - Poisson. \\(Pois(\\lambda)\\) \\(P(X=k)=\\frac{e^{-\\lambda}\\lambda^k}{k!}\\). \\(k \\in\\) {\\(0,1,2,...\\)} \\(\\lambda\\) \\(\\lambda\\) \\(e^{\\lambda (e^t-1)}\\) Uniforme. \\(Unif(a,b)\\) \\(f(x)=\\frac{1}{b-a}.\\) \\(x \\in (a,b)\\) \\(\\frac{a+b}{2}\\) \\(\\frac{(b-a)^2}{12}\\) \\(\\frac{e^{tb}-e^{ta}}{t(b-a)}\\) Normal. \\(N(\\mu, \\sigma^2)\\) \\(f(x)=\\frac{1}{\\sigma\\sqrt{2 \\pi}}e^{-(x-\\mu)^2/(2\\sigma^2)}\\). \\(x\\in (-\\infty, \\infty)\\) \\(\\mu\\) \\(\\sigma^2\\) \\(e^{t\\mu+\\frac{\\sigma^2t^2}{2}}\\) Exponencial. \\(Expo(\\lambda)\\) \\(f(X)=\\lambda e^{-\\lambda x}\\). \\(x\\in (0,\\infty)\\) \\(\\frac{1}{\\lambda}\\) \\(\\frac{1}{\\lambda^2}\\) \\(\\frac{\\lambda}{\\lambda -t}, t&lt;\\lambda\\) Gamma. \\(Gamma(\\alpha,\\lambda)\\) \\(f(x)=\\frac{1}{\\Gamma(\\alpha)}(\\lambda x)^{\\alpha}e^{\\lambda x \\frac{1}{x}}\\) \\(\\frac{\\alpha}{\\lambda}\\) \\(\\frac{\\alpha}{\\lambda^2}\\) \\((\\frac{\\lambda}{\\lambda -t}^{\\alpha}),t&lt;\\lambda\\) Beta. \\(Beta(a,b)\\) \\(f(x)=\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}x^{a-1}(1-x)^{b-1}\\). \\(x \\in (0,1)\\) \\(\\mu=\\frac{a}{a+b}\\) \\(\\frac{\\mu(1-\\mu)}{(a+b+1)}\\) - Log-Normal. \\(LN(\\mu, \\sigma^2)\\) \\(f(x)=\\frac{1}{x\\sigma\\sqrt{2 \\pi}}e^{-(logx-\\mu)^2/(2\\sigma^2)}\\). \\(x\\in (0, \\infty)\\) \\(\\theta=e^{\\mu + \\sigma^2/2}\\) \\(\\theta^2(e^{\\sigma^2}-1)\\) no existe Chi-Cuadrado. \\(X^2_n\\) \\(\\frac{1}{2^{n/2}\\Gamma(n/2)x^{n/2}e^{-x/2}}\\). \\(x\\in (0,\\infty)\\) \\(n\\) \\(2n\\) \\((1-2t)^{-n/2}, t&lt;1/2\\) T-Student. \\(t_n\\) \\(\\frac{\\Gamma((n+1)/2)}{\\sqrt{n \\pi}\\Gamma(n/2)}\\). \\(x\\in(-\\infty,\\infty)\\) \\(0\\)si\\(n&gt;1\\) \\(\\frac{n}{n-2}\\) si \\(n&gt;2\\) no existe "]
]
